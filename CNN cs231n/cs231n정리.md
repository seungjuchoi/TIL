
# History
- 5억 4천년의 삼엽충이 눈을 가지면서 진화의 빅뱅이 일어남
- 면이 아니라 선을 가지고 인식
- 1966년이 CV의 생일, AI 연구소 설립 in MIT -> CV의 50주년

# Intro
- Deep learning의 중요한 점은 구조가 계층적이라는 것이다.
- 인간의 vision은 복잡하다.하지만 하나씩 들여다 보자. 첫번째는 Edge image 선인식이다.두번째는 2(1/2)D, 마지막이 3D화이다.
- Black&white filter 같은 얼굴인식이 생기고 속도가 굉장히 빠르게 발전했다.
- 인류는 찾는 것이 아니라 그것이 무엇인지 인식하는 것에 집중(Feature)하고 있다. 호랑이인지 전체를 보기 전에 얼굴만 보고 혹은 꼬리만 보고 도망칠지 결정해야 했다.
- Deep learning feature를 뽑아내는 것이 중요
- Image-net 1.5milion  1000 object구분하는 것, 2012년에서는 CNN이 winner. 2012년 이후로는 모두 CNN위주가 된다. 이 분야에서 Back propergation의 본격적으로 쓰이기 시작했다.

# Linear classifier
- 선형 분류: Score 함수와 Loss 함수를 통해 선형화 시킨다. 예를 들어 Image 같은 data를 2차원 좌표의 벡터나 점으로 매핑한다. Convolution Neural Network에서는 비슷한 방법을 취하지만 훨씬 복잡하다.
- Softmax classifier: SVM만큼 유명한 분류기로 SVM과 loss 함수가 다르다. Multiple class의 일반화다. SVM과 달리 각 class마다 output을 scores로 다루는 데 좀더 직관적인 output을 주고 짧은 확률적 해석을 제공한다.

# K-NN
## CIFAR-10소개와 단순 비교방법
- 간단하면서 유명한 이미지 분류 데이터셋 중의 하나 ![](http://aikorea.org/cs231n/assets/nn.jpg)
- 두개의 이미지를 비교하는 간단한 방법은 빼는 것: 두 이미지가 똑같을 경우에는 결과가 0일 것이고, 두 이미지가 매우 다르다면 결과값이 클 것이다. 38.6%밖에 안됨
  - L1 Distance: Manhattan ![](https://en.wiktionary.org/wiki/File:Manhattan_distance.svg)
  - L2 Distance: **Euclidean** ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/dc0281a964ec758cca02ab9ef91a7f54ac00d4b7)

## K-NN 정의
- 위와 같은 단순 비교방법보다 뛰어난 첫번째 방법으로 하나만 비교하는 것이 아니라 인접한 k개의 Image를 찾는 것이다.
- 최근접 알고리즘으로 가장 간단한 ML 알고리즘이다.
- k개의 최근접 이웃 사이에서 가장 공통적인 항목에 할당되는 객체로 과반수 의결에 의해 분류한다. k가 커질수록 Outliner가 강인해주지고 경계가 부드러워진다.
- Instance-based learning: memory-based learning이라고도 함. memory에 저장된 instance를 기반으로 새로운 문제를 비교하는 방식, 따라서 모든 데이터를 기억해야 한다. 너무 많은 계산량을 요구하는 것과 모든 데이터를 저장하고 있어야하는 것이 K-NN의 대표적인 단점
- lazy learning: 지역적이고 모든 계산이 끝날때까지 답이 나오지 않는다. 일반화가 query가 모두 처리될때까지 지속적으로 연기되는 것을 의미한다.
- 거리를 n이라고 가정하면 간단한 가중치 스키마는 1/n의 가중치를 주는 것이다.
- 거리는 유클리드를 많이 사용한다.
- k를 경험적으로 선택하는 방법은 부트스트랩이다.


## hyperparameter 개선을 위한 Validation set
- k-nearest neighbor 분류기는 k를 정해줘야 한다. 이는 유효한 데이터set에 의해 튜닝되는 hyper parameter이다.
- 머신러닝 알고리즘을 디자인할 때, 테스트 셋은 매우 귀한 리소스이고, 이론적으로는 실제로 알고리즘을 평가할 때인 맨 마지막 단 한 번을 제외하고는 절대 쳐다봐서는 안 된다.
- 우리가 테스트 셋을 사용하여 hyperparameter 들을 튜닝했다는 것은 곧 우리가 테스트 셋을 마치 학습 데이터셋(트레이닝 셋)처럼 사용한 것이고, 우리 모델의 테스트 셋에서의 성능은 실제로 다른 데이터에 적용할 때에 비해 너무 낙관적이게 되어버린다. 이것을 테스트 셋에 overfit이라고 한다.
- 해결책1: 검증 셋(validation set) 으로 불리는, 약간 적은 수의 트레이닝 셋과 나머지로 나눈다. CIFAR-10 데이터셋을 예로 들면, 학습 이미지들 중에 49,000 장을 트레이닝 셋으로 삼고, 나머지 1,000 개를 검증으로 남겨둔다.
- 해결책2: 교차 검증을 한다. 검증 Set을 바꿔가면서 검증한다. 보통 교차 검증보다 하나의 검증 셋을 정해놓는 것을 선호한다. 계산량이 많기때문이다.
- hyperparameter 개수가 매우 많다면, 검증 데이터셋의 크기를 늘리는게 좋다.

## K-NN의 장점과 한계
- 학습시에는 계산량이 거의 없고 구현이 쉽다. 그냥 저장만 하면 된다. 그런데 테스트시에는 계산량이 많이 진다. 때문에 차원이 낮은 데이터의 경우에 좋다. 이미지는 매우 고차원이라 적합하지 않다.
- k-Nearest Neighbor는 이런 상황에 불리하다. Shift된 사진 눈코입이 없는 사진, 어두운 사진. 이미지의 클래스보다 배경이나 이미지의 전체적인 색깔 분포 등에 더 큰 영향을 받기 때문이다.
- 고양이를 인지하는 것이 여려운이유는 RGB 데이터가 많고 자세, 밝기, 각도에 따라 그 데이터가 너무 크게 변화하기 때문이다.
- 현재의 kNN 분류기가 너무 느리다면, 이를 가속하기 위해 Approximate Nearest Neighbor 라이브러리 (e.g. FLANN)를 사용하는 것을 고려해보라. (성능은 조금 떨어질 것이다)
- Linear classification는 Circle model에 약하다. wx+b 구조는 1차 함수와 비슷. gray scale의 경우는 사용 하기 힘들다.

# Linear classifier
# Image classfication에서 두가지 Function
- Score function: 선형 함수, Pixel data를 넣으면 class score로 계산해주는 파라미터화된(w) 함수
- Loss function: 특정 paraemter를 적용시켜 score함수를 만들었을 때 실제 데이터와 얼마나 차이나는 가에 대해 parameter의 정확도를 측정하는 함수 (SVM/Softmax)

- 그리고 세번째 작업, **Optimazation** 은 Loss 함수가 최소화되는 최적은 Parameter값을 찾는 것이다.
- Score function은 복잡한 형태로 확장되지만 Loss와 Optimization은 거의 변화가 없다.
- SVM의 Loss 함수의 볼록 함수이기 때문에 이상하게 생각할지 모른다. 몇가지 전략을 살펴보자.


# Loss 함수 전략
- **첫번째**, 무작위 탐색 w값을 랜덤하게 추출하여 비교한다. loss가 가장 적을 때는 기억하는 간단한 min알고리즘이다.
- **두번째**, 무작위 국소 탐색, 임의의 W에서 시작하여 또다른 임의의 방향으로 살짝 움직였을 때 Loss를 비교하여 거기로 움직이고 다시 탐색함.
- **세번째**, 그라디언트 따라가기, 손실함수는 gradient와 관계가 있다. 모든 차원을 하나씩 돌아가면서 그 방향으로 작은 변화 h를 줬을 때, 손실함수(loss function)의 값이 얼마나 변하는지를 구해서, 그 방향의 편미분 값을 계산한다.
- 방향은 gradient로 알 수 있지만 그 속도 그러니까 얼마만큼 가야하는 가는 알 수 없는데 그것을 Step 크기라고 명명하고 중요한 parameter로 생각하면 된다. 이것은 학습 속도라고도 할 수 있다. 조심스럽게 결정해야 한다. 단점은 gradient를 계산하는 데 드는 비용은 당연히 parameter의 수의 따라 선형적으로 늘어난다. 요즘 NN은 수천만개의 파라미터도 많은데 이 경우 문제가 심각해진다.
- **네번째**, 미적분을 이용한 gradient: 미분을 이용해 해석적으로 gradient를 구하는 방법으로 근사치가 아닌 정확한 수식을 사용하기 때문에 계산이 빠르다. 하지만 수치적으로 구한 gradient과 다르게 구현하는 데 실수하기 쉽다. 그래서 세번째 방법과 비교를 해야하는 과정이 필요한데 이것을 gradient check라고 한다.

## gradient 하강(descent)
```
while True:
  weights_grad = evaluate_gradient(loss_fun, data, weights)
  weights += - step_size * weights_grad # 파라미터 업데이트(parameter update)
```
이 단순한 loop가 NN의 중심이다. 현재로는 이 gradient 하강이 손실함수를 최적화하는 용도로 많이 쓰인다. 결과에 만족할 때까지 gradient를 따라서 움직인다는 기본적인 개념은 안바뀐다. 대규모의 응용사례에서 mini-batch 그라디언 하강은 좋은 대안이 되는데 학습 데이터를 배치만 이용해서 그라이언트를 구하는 것이다. 예를 들어 120만개 중에 256개짜리 batch만을 이용해서 gradient를 구하고 parameter를 업데이트 한다.

## 단순한 미니배치 (minibatch) 그라디언트(gradient) 업데이트
```
while True:
  data_batch = sample_training_data(data, 256) # 예제 256개짜리 미니배치(mini-batch)
  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)
  weights += - step_size * weights_grad # 파라미터 업데이트(parameter update)
```
- 손실함수(loss function)가 고차원의 울퉁불퉁한 지형이고, 이 지형에서 아래쪽으로 내려가는 것으로 직관적인 설명을 발전시켰다. 이에 대한 비유는 눈가린 등산객이 하산하는 것이었다. 특히, SVM의 손실함수(loss function)가 부분적으로 선형(linear)인 밥공기 모양이라는 것을 확인했다.
- 손실함수(loss function)을 최적화시킨다는 개념을, 아무 데서나 시작해서 더 나아지는 쪽으로 한걸음 한걸음 나은 쪽으로 가서 최적화시킨다는 반복적으로 개선의 측면으로 운을 띄워봤고
- 함수의 그라디언트(gradient)는 그 함수값이 감소하는 가장 빠른 방향이라는 점을 알아봤고, 이것을 유한차이(finite difference, 즉 미분할 때 h의 값이 유한하다는 의미)를 이용하여 단순무식하게 수치적으로 어림잡아 계산하는 방법도 알아보았다.
- 파라미터(parameter/weight)를 업데이트할 때, 한 번에 얼마나 움직여야하는지(혹은 학습속도)를 딱 맞게 설정하는 것이 까다로운 문제라는 것도 알아보았다. 이 값이 너무 낮으면 너무 느려지고, 너무 높으면 빨라지지만 위험한 점이 있다. 이 장단점에 대해 다음 섹션에서 자세하게 알아볼 것이다.
- 그라디언트(gradient)를 계산할 때 수치적인 방법과 해석적인 방법의 장단점을 알아보았다. 수치적인 그라디언트(gradient)는 단순하지만, 근사값이고 비효율적이다. 해석적인 그라디언트(gradient)는 정확하고 빠르지만 손으로 계산해야 되서 실수를 할 수 있다. 따라서 실제 응용에서는 해석적인 그라디언트(gradient)을 쓰고, 그라디언트 체크(gradient check)라는 수치적인 그라디언트(gradient)와 비교/검증하는 과정을 거친다.
- 반복적으로 루프(loop)를 돌려서 그라디언트(gradient)를 계산하고 파라미터(parameter/weight)를 업데이트하는 그라디언트 하강 (Gradient Descent) 알고리즘을 소개했다.
- **손실함수(loss function)를 파라미터(parameter/weight)로 미분하여 그라디언트(gradient)를 계산하는 법(과 그에 대한 직관적인 이해)가 신경망(neural network)를 디자인하고 학습시키고 이해하는데 있어 가장 중요한 기술이라는 점을 기억하자.**
- **그라디언(gradient)를 해석적으로 구할 때 연쇄법칙을 이용한, backpropagation이라고도 불리는 효율적인 방법을 사용하면 컨볼루션 신경망 (Convolutional Neural Networks)을 포함한 모든 종류의 신경망(Neural Networks)에서 쓰이는 상대적으로 일반적인 손실함수(loss function)를 효율적으로 최적화할 수 있다.**

# 신경망 소개
- F는 손실함수, Input으로 들어오는 x,w는 Input과 Weight로 Parameter를 계산하여 Gradient를 구하고 이를 다시 Parameter를 업데이트한다.
- Pradient는 편미분 값드의 벡터로 정의한다. 심플하게 x에 대한 편미분이라는 정확한 표현대신 x에 대한 gradient라고 표현하자.
- gradient는 f의 입력값에 대한 민감도로 볼 수 있다.
- Chain rule을 적용하여 Gradient를 계산하는 방법중에 하나.
- 신경망을 효과적으로 설계하는 데 중요한 포인트
- 함수의 Gradient를 의미: ∇f(x)
- [dfdx,dfdy,dfdz] 변수로 Gradient가 표현되는데 이는 f에 대한 변수 x,y,z의 민감도(sensitivity) 보여준다.
- dfdq는 dz로 축약

# Backpropagation
- Backpropagation은 네트워크 전체에 대해 반복적인 연쇄 법칙(Chain rule)을 적용하여 그라디언트(Gradient)를 계산하는 방법 중 하나
- 신경망을 효과적으로 개발하고, 디자인하고 디버그하는 데 중요
- 굉장히 지역적인(local) 프로세스가 backpropagation이다. 완전히 독립적으로 값들을 계산할 수 있다.
- 연쇄법칙 덕분에 이러한 각 입력에 대한 추가 곱셉은 복잡한 NN회로에서는 상대적으로 무시 가능하다
- add gate, max gate, multiply gate의 의미 파악
- 설계에 앞서 쉬운 예제부터 시작하고 직접 write out 하는 것이 도움이 될것이라고 함.
- 드디어, 다음 강의 부터 NN의 정의와 Backpropagation이 주는 효율적 계산에 대해서 알아보려함.

# 연쇄 법칙 (Chain rule)
- 응?

# 신경망 설명
- 기존의 선형분류섹션에서는 s=Wx식의 계산이었으나, 신경망에서는 s=W2max(0,W1x)의 계산을 한다.
- W1은 100.3072의 행렬로서 이미지를 100차원짜리 중간단계로 벡터로 전환하는 정도로 생각해볼 수 있다. 0이하의 값은 0으로 막아버린다.
- 비선형성이 계산되어 결적이라는 점에 주목. 비선형성이 없다면 행렬들은 서로 겁해져서 하나의 행렬이 되고 예측 스코어도 역시 그냥 선형 함수가 된다.
- 이 비선형성이 wiggle을 찾을 수 있게 하고 W2,W1는 확률 그라디언트로 학습시키고 그라디언트들은 연쇄법칙과 backpropagation으로 계산하여 구한다.

# 뉴런 하나 모델링
- 생물학점 뉴런에서 그 의미를 빌려왔다.
- 86 billion neurons
- 10^14 - 10^15 synapses
- Coarse model.
- Single neuron as a linear classifier
